flowchart TB
    subgraph INPUT["ğŸ“¥ INPUT - AI INTERVIEW"]
        I1["Interview Configuration<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Role: Senior Frontend Developer<br/>â€¢ Level: Senior<br/>â€¢ Tech Stack: React, TypeScript, Node.js<br/>â€¢ Question Mode: Provided/Generated<br/>â€¢ Question Count: 5<br/>â€¢ Company Info: Optional"]
        
        I2["Pre-defined Questions<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Q1: Tell me about yourself<br/>Q2: Why do you want this role?<br/>Q3: Describe a challenging project<br/>Q4: How do you handle conflicts?<br/>Q5: What are your strengths?"]
        
        I3["Candidate Voice Input<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Real-time voice stream<br/>via WebRTC"]
    end
    
    subgraph ORCHESTRATION["ğŸ›ï¸ VAPI.AI ORCHESTRATION"]
        VAPI["Vapi.ai SDK<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ WebRTC Connection<br/>â€¢ Real-time Bidirectional Voice<br/>â€¢ Event Management<br/>â€¢ Message Routing"]
    end
    
    subgraph PROCESSING["âš™ï¸ AI PROCESSING PIPELINE"]
        subgraph STT["ğŸ¤ Speech-to-Text"]
            DEEPGRAM["Deepgram Nova-2<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Real-time Transcription<br/>â€¢ Language: English<br/>â€¢ Model: nova-2<br/>â€¢ Accuracy: High"]
        end
        
        subgraph CONVERSATION["ğŸ’¬ Conversation Engine"]
            GPT4["OpenAI GPT-4<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Natural Interviewer Responses<br/>â€¢ Context-aware Questions<br/>â€¢ Follow-up Questions<br/>â€¢ Professional Tone"]
        end
        
        subgraph TTS["ğŸ”Š Text-to-Speech"]
            ELEVENLABS["11Labs Voice Synthesis<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Voice: Sarah<br/>â€¢ Stability: 0.4<br/>â€¢ Similarity Boost: 0.8<br/>â€¢ Speed: 0.9<br/>â€¢ Human-like Voice"]
        end
        
        subgraph TRANSCRIPT["ğŸ“ Transcript Collection"]
            COLLECT["Real-time Message Collection<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ User Messages<br/>â€¢ AI Messages<br/>â€¢ Final Transcripts<br/>â€¢ Q&A Pairs Extraction"]
        end
    end
    
    subgraph OUTPUT["ğŸ“¤ OUTPUT - INTERVIEW DATA"]
        O1["Full Transcript<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Complete conversation text<br/>User: ...<br/>AI: ..."]
        
        O2["Structured Q&A Pairs<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Turns Array:<br/>[{<br/>  orderIndex: 1,<br/>  questionText: '...',<br/>  answerText: '...',<br/>  questionCategory: 'BEHAVIORAL'<br/>}, ...]"]
        
        O3["Interview Metadata<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Interview ID<br/>â€¢ Status: IN_PROGRESS â†’ COMPLETED<br/>â€¢ Duration<br/>â€¢ Application ID (if linked)"]
    end
    
    subgraph EVALUATION["ğŸ“Š AI EVALUATION & ANALYSIS"]
        E1["Evaluation Input<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Full Transcript<br/>â€¢ Structured Turns (Q&A)<br/>â€¢ Seniority Level<br/>â€¢ Must-have Keywords<br/>â€¢ Nice-to-have Keywords"]
        
        E2{"Evaluation Mode?"}
        
        subgraph GEMINI["ğŸ§  Google Gemini 2.5 Flash"]
            G1["Build Analysis Prompt<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>6 Evaluation Criteria:<br/>1. Length (25%)<br/>2. Structure (20%)<br/>3. Examples (20%)<br/>4. Confidence (10%)<br/>5. Keyword Match (15%)<br/>6. Relevance (10%)"]
            
            G2["Question Type Adjustments<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Technical: +keywordMatch, +relevance<br/>â€¢ Behavioral: +structure, +examples<br/>â€¢ General: Default weights"]
            
            G3["Generate Structured JSON<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Overall Score (0-100)<br/>â€¢ Recommendation (HIRE/CONSIDER/REJECT)<br/>â€¢ Category Scores (5 categories)<br/>â€¢ Per-question Scores & Feedback"]
        end
        
        subgraph RULE_BASED["ğŸ“‹ Rule-based Fallback"]
            R1["Heuristic Scoring<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Word count analysis<br/>â€¢ Structure detection (STAR method)<br/>â€¢ Example detection<br/>â€¢ Filler word counting<br/>â€¢ Keyword matching<br/>â€¢ Relevance (Jaccard similarity)"]
            
            R2["Calculate Scores<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Same 6 criteria as Gemini<br/>but using rule-based logic"]
        end
    end
    
    subgraph RESULT["âœ… FINAL RESULT"]
        R3["Interview Feedback<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>{<br/>  overallScore: 85,<br/>  recommendation: 'HIRE',<br/>  summary: '...',<br/>  strengths: [...],<br/>  areasForImprovement: [...],<br/>  categoryScores: [...],<br/>  perQuestion: [...]<br/>}"]
        
        R4["Database Updates<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Interview.status = COMPLETED<br/>â€¢ Interview.overallScore = 85<br/>â€¢ Interview.recommendation = 'HIRE'<br/>â€¢ InterviewExchange scores updated<br/>â€¢ Application.status = INTERVIEWED"]
        
        R5["Notifications<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>â€¢ Email to Recruiter<br/>â€¢ Interview completed notification<br/>â€¢ Feedback available"]
    end
    
    %% Input Flow
    I1 --> VAPI
    I2 --> VAPI
    I3 --> VAPI
    
    %% Processing Flow
    VAPI -->|Voice Stream| DEEPGRAM
    VAPI -->|Text| GPT4
    GPT4 -->|Response Text| ELEVENLABS
    ELEVENLABS -->|Voice Output| VAPI
    DEEPGRAM -->|Transcription| COLLECT
    GPT4 -->|Messages| COLLECT
    COLLECT --> O1
    COLLECT --> O2
    
    %% Evaluation Flow
    O1 --> E1
    O2 --> E1
    E1 --> E2
    E2 -->|GEMINI Mode| G1
    E2 -->|RULE_BASED Mode| R1
    G1 --> G2 --> G3 --> R3
    R1 --> R2 --> R3
    
    %% Result Flow
    R3 --> R4
    R4 --> R5
    
    %% Styling
    classDef input fill:#e3f2fd,stroke:#0277bd,stroke-width:3px,color:#000
    classDef orchestration fill:#fff3e0,stroke:#e65100,stroke-width:3px,color:#000
    classDef stt fill:#f3e5f5,stroke:#4a148c,stroke-width:2px,color:#000
    classDef conversation fill:#e8f5e9,stroke:#1b5e20,stroke-width:2px,color:#000
    classDef tts fill:#fff9c4,stroke:#f57f17,stroke-width:2px,color:#000
    classDef transcript fill:#fce4ec,stroke:#880e4f,stroke-width:2px,color:#000
    classDef output fill:#e0f2f1,stroke:#004d40,stroke-width:2px,color:#000
    classDef evaluation fill:#ffebee,stroke:#c62828,stroke-width:2px,color:#000
    classDef gemini fill:#e1bee7,stroke:#4a148c,stroke-width:2px,color:#000
    classDef rule fill:#fffde7,stroke:#f57f17,stroke-width:2px,color:#000
    classDef result fill:#c8e6c9,stroke:#1b5e20,stroke-width:3px,color:#000
    classDef decision fill:#fff9c4,stroke:#f9a825,stroke-width:2px,color:#000
    
    class I1,I2,I3,INPUT input
    class VAPI,ORCHESTRATION orchestration
    class DEEPGRAM,STT stt
    class GPT4,CONVERSATION conversation
    class ELEVENLABS,TTS tts
    class COLLECT,TRANSCRIPT transcript
    class O1,O2,O3,OUTPUT output
    class E1,E2,EVALUATION evaluation
    class G1,G2,G3,GEMINI gemini
    class R1,R2,RULE_BASED rule
    class R3,R4,R5,RESULT result
    class E2 decision

